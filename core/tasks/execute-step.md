# execute-step

## Execution Notice
You are about to execute a **Thinking Step** from your iterative thinking plan. This task enforces step-by-step progression with validation gates, ensuring each step builds on previous insights before advancing.

## Method Description
**Universal Cognitive-Adaptive Iterative Thinking (UCAIT) Execution**: Executes universal thinking steps integrating domain-agnostic cognitive frameworks applicable across all fields - science, philosophy, personal decisions, creative projects, academic research.

**Core Principle**: Enforce disciplined multi-layered thinking combining Polya's universal problem-solving, computational thinking, critical reasoning, lateral thinking, and systems analysis for breakthrough insights across any domain.

**Enforcement Mechanisms**:
- Cannot skip to later steps without completing prerequisites
- Validation criteria must be met before step completion
- Insights and deliverables captured before progression
- Time awareness without strict enforcement

## Interactive Flow

### Execution Mode Detection
**Auto-Execute Mode**: When called with "auto" parameter, execute all steps sequentially without individual confirmations
**Manual Mode**: Traditional step-by-step execution with confirmations

### Step 1: Validate Execution Context

**Check for Active Thinking Plan**:
If no active plan: "No thinking plan found. Please run '*create-thinking-plan' first."

**Auto-Execute Mode**:
If auto mode: "üöÄ EXECUTING FULL THINKING PLAN AUTOMATICALLY..."
- Show plan overview
- Begin sequential execution
- Skip to Step 2A (Auto Execution Loop)

**Manual Mode**:
**Check Current Step Status**:
- If current step already completed: "Step {N} already completed. Use '*plan-status' to see progress or '*execute-step {N+1}' for next step."
- If prerequisite steps incomplete: "Cannot execute Step {N}. Prerequisites not met: {list incomplete steps}"

### Step 2A: Auto Execution Loop (Auto Mode Only)

**For Each Step in Plan (Sequential)**:
```
‚è≥ EXECUTING STEP {N}: {step title}
Focus: {focus question}

üß† COGNITIVE PREPARATION PHASE:
- Assessing cognitive load and optimal depth for this step
- Personalizing approach based on complexity and user expertise
- Determining multi-layer thinking integration strategy

üîç WEB RESEARCH PHASE:
- Searching latest best practices for: {focus keywords}
- Gathering current industry approaches and case studies
- Identifying validation frameworks and common pitfalls

üéØ UNIVERSAL MULTI-LAYER THINKING EXECUTION:
[Layer 1: Polya's Universal Problem Understanding] - Systematic problem comprehension across any domain
[Layer 2: Computational Thinking] - Decomposition, pattern recognition, abstraction, algorithmic thinking  
[Layer 3: Universal Lateral Thinking] - SCAMPER + Six Hats applied across all domains of inquiry
[Layer 4: Universal Systems Analysis] - System boundaries, relationships, leverage points, feedback loops
[Layer 5: Conceptual Connection Mapping] - Cross-domain pattern visualization and insight networks
[Generate deliverables enhanced with universal multi-layer insights]

üîÑ METACOGNITIVE REFLECTION PHASE:
[Elements of Reasoning Review] - Purpose, assumptions, implications, perspectives
[Intellectual Standards Check] - Clarity, accuracy, precision, relevance, depth
[Assumption Challenging] - What assumptions need questioning?
[Perspective Broadening] - What alternative viewpoints exist?

üìä ENHANCED VALIDATION PHASE:
[Traditional Criteria Check] - Original step validation requirements
[Metacognitive Quality Assessment] - Thinking quality and depth evaluation
[Systems Perspective Validation] - Systems thinking integration verification
[Connection Quality Verification] - Visual and conceptual connection assessment

‚úÖ COMPLETED STEP {N}
Universal Insights: {5-layer universal insights with cross-domain validation}
Polya Understanding: {systematic problem comprehension achievements}
Computational Thinking: {decomposition, patterns, abstraction, algorithms applied}
Metacognitive Reflections: {elements of reasoning and standards assessment}
Systems Analysis: {boundaries, relationships, leverage points, feedback loops identified}
Conceptual Connections: {cross-domain patterns and insight networks mapped}
Web Research Applied: {list of universal searches and key findings}
Progress: {N}/{total} steps completed
---
```

**After All Steps Complete**:
```
üéâ THINKING PLAN COMPLETED
===========================

Total Steps Executed: {total}
Key Insights Summary: [consolidated insights]
Deliverables Created: [list all deliverables]
Decision Reached: [if applicable]

All insights and deliverables have been saved.
Use '*thinking-summary' for detailed analysis.
```

### Step 2: Step Initialization (Manual Mode)

**Display Step Context**:
```
EXECUTING THINKING STEP {N}
===========================

Title: {step title}
Focus Question: {focus question}
Status: IN PROGRESS

Methods Available: {list of methods}
Expected Deliverables: {list of deliverables}
```

### Step 3: Guided Step Execution

**Focus Question Engagement**:
"Let's focus on this step's core question: {focus question}

Based on your thinking plan, this step uses these methods: {methods list}

How would you like to approach this? I can:
1. Guide you through each method systematically  
2. Let you work freely and check progress periodically
3. Focus on one specific method you prefer
4. Start with a different approach you have in mind"

**CAIT Multi-Layer Method Application**:

**Phase 0: Cognitive Preparation & Assessment**
Optimize cognitive performance before method application:

1. **Cognitive Load Assessment**:
   - Evaluate step complexity vs. user capability and expertise level
   - Assess cognitive fatigue and recommend optimal depth
   - Determine personalization factors (experience, domain knowledge, preferences)
   - **Web Search**: "cognitive load optimization {problem domain} universal best practices"

2. **Multi-Layer Integration Planning**:
   - Plan lateral thinking integration points
   - Identify systems thinking mapping opportunities  
   - Determine visual thinking and connection strategies
   - Plan metacognitive reflection checkpoints

**Phase A: Real-Time Research Foundation**
Establish current knowledge base with enhanced research:

1. **Universal Best Practices Search**:
   - **Web Search**: "domain-agnostic best practices {focus question keywords} 2024"
   - **Web Search**: "{step methods} current approaches field experts"
   - **Web Search**: "metacognitive strategies {focus area} universal thinking frameworks"
   - **Capture**: State-of-the-art methodologies and cognitive approaches across disciplines

2. **Cross-Domain Research**:
   - **Web Search**: "case studies across disciplines {problem domain} successful solutions"
   - **Web Search**: "scholarly research {focus question topic} expert insights"
   - **Web Search**: "systems thinking applications {problem domain} universal principles"
   - **Capture**: Real-world examples and expert perspectives from multiple fields

3. **Universal Validation Research**:
   - **Web Search**: "common methodological mistakes {step focus} lessons learned"
   - **Web Search**: "validation frameworks {analysis type} cross-domain reliability"
   - **Web Search**: "critical thinking standards {domain} universal quality assessment"
   - **Capture**: Pitfalls to avoid and validation approaches applicable across domains

**Phase B: Multi-Layer Method Execution**
Apply enhanced method integration with cognitive frameworks:

**Example: Step 2 of Medium complexity (Universal Causal Analysis)**

**Layer 1: Polya's Universal Problem Understanding**:
- **Web Search**: "universal causal analysis techniques {problem type} domain-agnostic"
- **Understand the Problem**: What are we trying to explain causally across any domain?
- **Web Search**: "5 whys technique applications {field} systematic questioning"
- Apply 5 Whys with universal questioning approach
- **Web Search**: "fishbone diagram applications {domain}" if multi-factor
- Apply causal mapping enhanced with domain-appropriate factors
- **Web Search**: "evidence validation {problem domain} cross-disciplinary methodologies"

**Layer 2: Computational Thinking Integration**:
- **Decomposition**: Break complex causation into manageable causal components
- **Pattern Recognition**: Identify recurring causal patterns across similar phenomena
- **Abstraction**: Extract essential causal relationships, ignore irrelevant details
- **Algorithmic Thinking**: Develop systematic process for tracing causation

**Layer 3: Universal Lateral Thinking**:
- **SCAMPER Application**: 
  - Substitute: "What if we substituted this causal explanation with another framework?"
  - Combine: "What if multiple causal theories combined in unexpected ways?"
  - Adapt: "How do other fields handle similar causal questions?"
  - Modify: "What if we magnified or minimized certain causal factors?"
  - Put to other uses: "How else could these causal relationships be interpreted?"
  - Eliminate: "What if certain assumed causes don't actually exist?"
  - Reverse: "What if effects are actually causes and vice versa?"

- **Six Thinking Hats**:
  - White Hat: "What factual evidence do we have about causation?"
  - Red Hat: "What intuitions or emotions point to underlying causes?"
  - Black Hat: "What risks arise from incorrectly identifying causation?"
  - Yellow Hat: "What benefits come from understanding true causation?"
  - Green Hat: "What creative alternative causal explanations exist?"
  - Blue Hat: "How can we manage our causal investigation process?"

**Layer 4: Universal Systems Analysis**:
- **System Boundary Definition**: "What constitutes the causal system we're analyzing?"
- **Element Relationship Mapping**: "How do different factors relate within this causal system?"
- **Leverage Point Identification**: "Where can small changes produce large causal effects?"
- **Feedback Loop Analysis**: "What self-reinforcing or balancing causal loops exist?"
- **Web Search**: "systems thinking causal analysis {problem domain} universal principles"

**Layer 5: Conceptual Connection Mapping**:
- **Causal Visualization**: Create visual representations of causal relationships
- **Cross-Domain Pattern Recognition**: Identify causal patterns that transcend specific domains
- **Causal Network Diagrams**: Map complex causation as interconnected system
- **Temporal Visualization**: Understand how causation unfolds over time

**Throughout Multi-Layer Execution**:
- Keep focus question visible across all layers
- **Continuously search** for layer-specific information as insights emerge
- Cross-reference insights between different thinking layers
- Note unexpected connections revealed by multi-layer analysis
- Build toward enhanced deliverables incorporating all layer insights

### Step 4: Enhanced Insight Capture & Metacognitive Synthesis

**Phase C: Metacognitive Reflection**
Apply Paul-Elder Critical Thinking Framework for systematic reflection:

**Elements of Reasoning Review**:
- **Purpose**: "What was the specific purpose of this thinking step and was it achieved?"
- **Question**: "What question was I trying to answer and did I answer it thoroughly?"
- **Information**: "What information did I use and what information do I still need?"
- **Concepts**: "What key concepts/ideas were involved and how well do I understand them?"
- **Assumptions**: "What assumptions did I make and which should be questioned?"
- **Implications**: "What are the implications and consequences of my thinking?"
- **Point of View**: "What perspective did I take and what alternative perspectives exist?"
- **Interpretation**: "How did I interpret the information and could it be interpreted differently?"

**Intellectual Standards Assessment**:
- **Clarity**: "Is my thinking clear and understandable to others?"
- **Accuracy**: "Is my thinking accurate and supported by evidence?"
- **Precision**: "Is my thinking precise and specific enough?"
- **Relevance**: "Is my thinking relevant to the core question?"
- **Depth**: "Did I think deeply enough about this issue?"
- **Breadth**: "Did I consider multiple perspectives and viewpoints?"
- **Logic**: "Is my reasoning logical and coherent?"
- **Fairness**: "Was I fair and unbiased in my thinking?"

**Universal Insight Harvesting**:
"Let's capture insights across all universal thinking layers:

**Polya Problem Understanding**: What did you learn about the problem through systematic universal analysis?
**Computational Thinking Insights**: What emerged from decomposition, pattern recognition, abstraction, and algorithmic thinking?
**Lateral Thinking Breakthroughs**: What unexpected connections or ideas emerged from SCAMPER and Six Hats across domains?
**Systems Analysis Insights**: What systemic patterns, leverage points, or feedback loops did you identify in the problem system?
**Conceptual Connections**: What cross-domain patterns and insight networks became clear through visualization?
**Metacognitive Realizations**: What did you learn about your own thinking process across all layers?
**Universal Synthesis**: How do insights from different layers combine to create domain-transcendent understanding?"

**Universal Deliverable Generation**:
Create comprehensive deliverables incorporating universal multi-layer insights:
- Use designated templates enhanced with universal framework sections
- Ensure deliverables capture insights from all five universal thinking layers
- Include cross-domain applicability assessment
- Link to previous step outputs with universal systems perspective
- Add conceptual connection maps showing cross-domain patterns
- Document assumptions challenged and perspectives broadened across disciplines

### Step 5: Enhanced Multi-Layer Validation

**Enhanced Validation Framework**:
Review validation across all cognitive layers:

**Traditional Criteria Check**:
"Let's verify traditional step completion:
‚úì Criterion 1: {description} - [Check with user]
‚úì Criterion 2: {description} - [Check with user]  
‚úì Criterion 3: {description} - [Check with user]"

**Metacognitive Quality Assessment**:
"Let's assess thinking quality using Paul-Elder standards:
‚úì Clarity: Is the thinking clear and well-articulated?
‚úì Accuracy: Is the analysis accurate and evidence-based?
‚úì Precision: Is the thinking precise and specific enough?
‚úì Relevance: Does the analysis address the core question?
‚úì Depth: Is the analysis sufficiently deep and thorough?
‚úì Breadth: Were multiple perspectives considered?
‚úì Logic: Is the reasoning logical and coherent?
‚úì Fairness: Was the analysis fair and unbiased?"

**Polya Problem Understanding Validation**:
"Let's verify universal problem understanding:
‚úì Problem Comprehension: Was the problem understood systematically across its domain?
‚úì Universal Applicability: Could the understanding apply to similar problems in other fields?
‚úì Systematic Approach: Was a systematic method used for problem analysis?
‚úì Foundation Quality: Does this understanding provide a solid foundation for further analysis?"

**Computational Thinking Validation**:
"Let's verify computational thinking integration:
‚úì Decomposition Quality: Was the problem broken into meaningful, manageable components?
‚úì Pattern Recognition: Were important patterns identified and documented clearly?
‚úì Abstraction Effectiveness: Were essential elements extracted while ignoring irrelevant details?
‚úì Algorithmic Clarity: Was a clear step-by-step reasoning process developed?"

**Universal Systems Analysis Validation**:
"Let's verify universal systems thinking integration:
‚úì System Boundaries: Were appropriate system boundaries defined for the domain?
‚úì Element Relationships: Were connections between system components clearly identified?
‚úì Leverage Points: Were high-impact intervention points identified within the system?
‚úì Feedback Loops: Were important system loops and dynamics analyzed?
‚úì Universal Principles: Do the insights apply beyond the specific domain?"

**Conceptual Connection Validation**:
"Let's assess conceptual mapping and cross-domain connections:
‚úì Cross-Domain Patterns: Were patterns that transcend specific domains identified?
‚úì Insight Networks: Are connections between insights clearly mapped and meaningful?
‚úì Visual Clarity: Are conceptual representations clear and informative?
‚úì Connection Novelty: Were unexpected or innovative cross-domain connections discovered?
‚úì Universal Applicability: Do the connections have relevance beyond the immediate domain?"

**Universal Lateral Thinking Check**:
"Let's verify creative thinking integration across domains:
‚úì SCAMPER Application: Were SCAMPER techniques meaningfully applied across domain boundaries?
‚úì Six Hats Coverage: Were all thinking perspectives explored from multiple domain viewpoints?
‚úì Cross-Domain Creativity: Were novel ideas generated by connecting across different fields?
‚úì Alternative Perspectives: Were unconventional viewpoints from other domains considered?"

**Universal Completion Decision**:
- If all criteria met: "Step {N} completed successfully with universal cognitive depth across all domains!"
- If criteria missing: "Some criteria not yet met. Universal enhancement options:
  1. Continue working on this step with specific layer focus
  2. Address specific missing criteria (Polya/computational/metacognitive/systems/conceptual/lateral)
  3. Deepen specific universal thinking layer that needs more development
  4. Explore cross-domain applications to strengthen universal insights
  5. Mark step as 'sufficient' and proceed (not recommended for optimal cross-domain insight quality)
  6. Request cognitive load adjustment if universal framework seems overwhelming"

### Step 6: Progress Update & Next Actions

**Update Plan State**:
- Mark current step as completed
- Update session tracking (insights, time, deliverables)
- Set next step as current

**Progress Summary**:
```
STEP {N} COMPLETED
==================

Key Insights: {captured insights}
Deliverables Created: {list}

OVERALL PROGRESS: {completed steps} of {total steps} steps completed

Next Step: {next step title}
Focus: {next focus question}
```

**Next Actions**:
"Ready for the next step? You can:
- '*execute-step' to continue with Step {N+1}
- '*plan-status' to review overall progress
- '*thinking-summary' to synthesize insights so far
- '*adjust-plan' if you need to modify the approach
- Take a break and return later (progress is saved)"

## Step-Specific Execution Patterns

### Analysis Steps (Root Cause, First Principles, etc.)
- Apply systematic questioning techniques
- Build evidence-based conclusions
- Challenge assumptions explicitly
- Document reasoning chains

### Generation Steps (Solution Creation, Innovation, etc.)
- Use multiple creative methods
- Encourage diverse thinking
- Defer judgment during generation
- Capture all ideas before evaluation

### Evaluation Steps (Decision Analysis, Trade-offs, etc.)
- Apply structured comparison methods
- Use consistent evaluation criteria
- Perform sensitivity analysis where appropriate
- Document decision rationale

### Planning Steps (Implementation, Strategy, etc.)
- Focus on actionable outcomes
- Include risk mitigation
- Define success metrics
- Plan for monitoring and adaptation

## Output Format

### Step Execution Log
```yaml
step_execution:
  step_number: {N}
  step_title: "{title}"
  execution_date: "{timestamp}"
  
step_results:
  focus_question: "{question}"
  methods_used: ["{method1}", "{method2}"]
  key_insights: ["{insight1}", "{insight2}"]
  deliverables_created: ["{file1}", "{file2}"]
  validation_status: "completed" | "sufficient" | "incomplete"
  
progression:
  prerequisites_met: true
  validation_criteria_met: true
  ready_for_next_step: true
  next_step_number: {N+1}
  
session_context:
  cumulative_insights: ["{all insights so far}"]
  decision_trail: ["{decisions made}"]
```

### Deliverable Files
Each step produces its designated deliverables using appropriate templates and containing step-specific analysis.

## Integration Points

**With Thinking Plan**:
- Reads active thinking plan for step details
- Updates plan state with completion status
- Enforces prerequisite relationships

**With Agent State**:
- Maintains session context across steps
- Tracks cumulative insights and decisions
- Preserves progress for session resumption

**With Templates**:
- Uses step-specific templates for deliverable generation
- Ensures consistent formatting and content structure

**With Other Tasks**:
- May invoke specific analysis tasks (5-whys, TRIZ, etc.) within steps
- Coordinates with validation and synthesis tasks

## Validation Criteria

**Step Completion Quality**:
- Focus question adequately addressed
- Designated methods properly applied
- Key insights captured and documented
- Required deliverables produced

**Progressive Learning**:
- Each step builds on previous insights
- Connections between steps are explicit
- Understanding deepens through the sequence
- No critical insights or decisions lost

## Notes for Thinker

**Enforcement Balance**:
- Be firm about sequential progression (no skipping ahead)
- Be flexible about methods (user may have better approaches)
- Focus on insight quality and systematic progression
- Allow "sufficient" completion when perfect isn't practical

**Session Management**:
- Save progress frequently for interruption recovery
- Maintain thinking context across breaks
- Reference previous insights throughout execution
- Build narrative coherence across steps

**Adaptation Signals**:
- If user consistently struggles with planned methods, suggest plan adjustment
- If new information significantly changes problem understanding, pause to reassess complexity
- If insights suggest different approach, be open to plan modification